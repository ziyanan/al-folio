---
---

@string{aps = {American Physical Society,}}

@inproceedings{v2xsim2021,
  abbr={V2X-Sim},
  bibtex_show={true},
  title={V2X-Sim: A Virtual Collaborative Perception Dataset for Autonomous Driving.},
  author={Li, Yiming and An, Ziyan and Wang, Zixun and Zhong, Yiqi and Chen, Siheng and Feng, Chen},
  booktitle={IEEE International Conference on Computer Vision Workshops (ICCVW)},
  year={2021},
  abstract={Vehicle-to-everything (V2X), which denotes the collaboration between a vehicle and any entity in its surrounding, can fundamentally improve the perception in self-driving systems. As the individual perception rapidly advances, collaborative perception has made little progress due to the shortage of public V2X datasets. In this work, we present the V2X-Sim dataset, the first public large-scale collaborative perception dataset in autonomous driving. V2X-Sim provides: 1) well-synchronized recordings from roadside infrastructure and multiple vehicles at the intersection to enable collaborative perception, 2) multi-modality sensor streams to facilitate multi-modality  perception, 3) diverse well-annotated ground truth to support various downstream tasks including detection,  tracking, and segmentation. We seek to inspire research on multi-agent multi-modality multi-task perception, and our virtual dataset is promising to promote the development of collaborative perception before realistic datasets become widely available.},
  html={https://ai4ce.github.io/V2X-Sim/},
  pdf={V2X_Sim_ICCVW2021.pdf},
  selected={true}
}

@ARTICLE{9835036,  
abbr={V2X-Sim},
author={Li, Yiming and Ma, Dekun and An, Ziyan and Wang, Zixun and Zhong, Yiqi and Chen, Siheng and Feng, Chen},  
journal={IEEE Robotics and Automation Letters},   
title={V2X-Sim: Multi-Agent Collaborative Perception Dataset and Benchmark for Autonomous Driving},   
year={2022},  
volume={7},  
number={4},  
pages={10914-10921},  
doi={10.1109/LRA.2022.3192802},
selected={true}
}
